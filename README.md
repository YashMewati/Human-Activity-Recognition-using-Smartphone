# Human-Activity-Recognition-using-Smartphone

# Data 
30 participants performed activities of daily living while carrying a waist-mounted smartphone. The phone was configured to record two implemented sensors (accelerometer and gyroscope). For these time series the directors of the underlying study performed feature generation and generated the dataset by moving a fixed-width window of 2.56s over the series. 

# Labels Distributed 

![newplot (5)](https://user-images.githubusercontent.com/85125898/150678362-bc2b65e2-44f2-4b82-9e8b-270d1a66534e.png)

Although there are fluctuations in the label counts, the labels are quite equally distributed.

Assuming the participants had to walk the same number of stairs upwards as well as downwards and knowing the smartphones had a constant sampling rate, there should be the same amount of datapoints for walking upstairs and downstairs.
Disregarding the possibility of flawed data, the participants seem to walk roughly 10% faster downwards.

# Activity Exploration 

ğ€ğ«ğ ğ“ğ¡ğ ğ€ğœğ­ğ¢ğ¯ğ¢ğ­ğ¢ğğ¬ ğ’ğğ©ğšğ«ğšğ›ğ¥ğ?

The dataset is geared towards classifying the activity of the participant. Let us investigate the separability of the classes.

![__results___11_0](https://user-images.githubusercontent.com/85125898/150678462-d2074207-0cf1-43c5-9d5d-432b46a6f8e3.png)

In plot 1 you can clearly see the activities are mostly separable.

Plot 2 reveals personal information of the participants. Everybody has for example an unique/sparable walking style (on the upper right). Therefore the smartphone should be able to detect what you are doing and also who is using the smartphone (if you are moving around with it).


ğ‡ğ¨ğ° ğ†ğ¨ğ¨ğ ğ€ğ«ğ ğ“ğ¡ğ ğ€ğœğ­ğ¢ğ¯ğ¢ğ­ğ¢ğğ¬ ğ’ğğ©ğšğ«ğšğ›ğ¥ğ?

Without much preprocessing and parameter tuning a simple LGBMClassifier should work decently.

ğ€ğœğœğ®ğ«ğšğœğ² ğ¨ğ§ ğ­ğğ¬ğ­ğ¬ğğ­:	ğŸ.ğŸ—ğŸ“ğŸ“ğŸ•
With a basic untuned model the activity of the smartphone user can be predicted with an ğšğœğœğ®ğ«ğšğœğ² ğ¨ğŸ ğŸ—ğŸ“%.
This is pretty striking regarding six equally distributed labels.

# Participant Exploration


ğ‡ğ¨ğ° ğ†ğ¨ğ¨ğ ğ€ğ«ğ ğ­ğ¡ğ ğğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­ğ¬ ğ’ğğ©ğšğ«ğšğ›ğ¥ğ?

As we have seen in the second t-SNE plot the separability of the participants seem to vary regarding their activity. Let us investigate this a little bit by fitting the same basic model to the data of each activity separately.

![Human Activity Recognition using Smartphone Data with Machine Learning - Jupyter Notebook - Google Chrome 1_23_2022 6_03_38 PM](https://user-images.githubusercontent.com/85125898/150678631-7b491270-9ad3-40f7-9633-5acc78a0f814.png)

ğƒğğ­ğğœğ­ğ¢ğ§ğ  ğ­ğ¡ğ ğœğ¨ğ«ğ«ğğœğ­ ğ©ğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­ regarind their current activity is not alone possible but ğšğ¬ğ­ğ¨ğ§ğ¢ğ¬ğ¡ğ¢ğ§ğ  ğšğœğœğ®ğ«ğšğ­ğ regarding the 30 different persons (ğŸ—ğŸ’% ğ›ğ² ğ°ğšğ¥ğ¤ğ¢ğ§ğ  ğ¬ğ­ğ²ğ¥ğ).


ğ–ğ¡ğ¢ğœğ¡ ğ’ğğ§ğ¬ğ¨ğ« ğˆğ¬ ğŒğ¨ğ«ğ ğˆğ¦ğ©ğ¨ğ«ğ­ğšğ§ğ­ ğ…ğ¨ğ« ğ‚ğ¥ğšğ¬ğ¬ğ¢ğŸğ²ğ¢ğ§ğ  ğğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­ğ¬ ğğ² ğ–ğšğ¥ğ¤ğ¢ğ§ğ  ğ’ğ­ğ²ğ¥ğ?

![__results___19_0](https://user-images.githubusercontent.com/85125898/150678729-345b5da7-fe1f-4ab1-9352-9671806e3afe.png)

The accelerometer supplies slightly more information. Both sensors are important for classification and refraining from using both sensors will be a drawback for the quality of the model.


ğ‡ğ¨ğ° ğ‹ğ¨ğ§ğ  ğƒğ¨ğğ¬ ğ“ğ¡ğ ğğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­ ğ”ğ¬ğ ğ“ğ¡ğ ğ’ğ­ğšğ¢ğ«ğœğšğ¬ğ?

![__results___21_0](https://user-images.githubusercontent.com/85125898/150678777-8de22707-b964-4fd9-bd9c-e59e0e5707dd.png)

Nearly all participants have more data for walking upstairs than downstairs. Assuming an equal number of up- and down-walks the ğ©ğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­ğ¬ ğ§ğğğ ğ¥ğ¨ğ§ğ ğğ« ğ°ğšğ¥ğ¤ğ¢ğ§ğ  ğ®ğ©ğ¬ğ­ğšğ¢ğ«ğ¬.
Furthermore the range of the duration is narrow and adjusted to the conditions. A young person being ~50% fast in walking upstairs than an older one is reasonable.


ğ‡ğ¨ğ° ğŒğ®ğœğ¡ ğƒğ¨ğğ¬ ğ“ğ¡ğ ğ”ğ©-/ğƒğ¨ğ°ğ§ğ¬ğ­ğšğ¢ğ«ğ¬ ğ‘ğšğ­ğ¢ğ¨ ğ•ğšğ«ğ²?

![__results___23_0](https://user-images.githubusercontent.com/85125898/150678835-f5ac4e14-4ac4-4330-9b08-f2262d3f62f9.png)

There is a wide range in between the participants for their ğ«ğšğ­ğ¢ğ¨ ğ¨ğŸ ğ®ğ©-/ğğ¨ğ°ğ§-ğ°ğšğ¥ğ¤ğ¢ğ§ğ . Since this represents their physical condition I can imagine a ğœğ¨ğ«ğ«ğğ¥ğšğ­ğ¢ğ¨ğ§ ğ­ğ¨ ğ­ğ¡ğğ¢ğ« ğšğ ğ ğšğ§ğ ğ¡ğğšğ¥ğ­ğ¡ (ğ¬ğ©ğğœğ®ğ¥ğšğ­ğ¢ğ¯ğ).


ğ€ğ«ğ ğ“ğ¡ğğ«ğ ğ‚ğ¨ğ§ğ¬ğ©ğ¢ğœğ®ğ¢ğ­ğ¢ğğ¬ ğˆğ§ ğ“ğ¡ğ ğ’ğ­ğšğ¢ğ«ğœğšğ¬ğ ğ–ğšğ¥ğ¤ğ¢ğ§ğ  ğƒğ®ğ«ğšğ­ğ¢ğ¨ğ§ ğƒğ¢ğ¬ğ­ğ«ğ¢ğ›ğ®ğ­ğ¢ğ¨ğ§?

![__results___25_0](https://user-images.githubusercontent.com/85125898/150678900-fbd3d254-1199-4145-addc-49bf2b31abfd.png)

As aspected from most real world data the duration walking on the staircase is normally distributed


ğˆğ¬ ğ“ğ¡ğğ«ğ ğ€ ğ”ğ§ğ¢ğªğ®ğ ğ–ğšğ¥ğ¤ğ¢ğ§ğ  ğ’ğ­ğ²ğ¥ğ ğ…ğ¨ğ« ğ„ğšğœğ¡ ğğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­?

![__results___27_0](https://user-images.githubusercontent.com/85125898/150678927-8f383cec-3613-41d2-8ffb-137c1e6585e6.png)


ğ‡ğ¨ğ° ğ‹ğ¨ğ§ğ  ğƒğ¨ğğ¬ ğ“ğ¡ğ ğğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­ ğ–ğšğ¥ğ¤?

![__results___29_0](https://user-images.githubusercontent.com/85125898/150678952-4ec3af61-0f7a-437e-83c5-2de98d4a05bc.png)

Since the duration of each participant walking is distributed over a range I assume the participants had a fixed walking distance for their experiment rather than a fixed duration.


ğˆğ¬ ğ“ğ¡ğğ«ğ ğ€ ğ”ğ§ğ¢ğªğ®ğ ğ’ğ­ğšğ¢ğ«ğœğšğ¬ğ ğ–ğšğ¥ğ¤ğ¢ğ§ğ  ğ’ğ­ğ²ğ¥ğ ğ…ğ¨ğ« ğ„ğšğœğ¡ ğğšğ«ğ­ğ¢ğœğ¢ğ©ğšğ§ğ­?

![__results___31_0](https://user-images.githubusercontent.com/85125898/150678976-5962657f-bd62-466a-a6f3-567109e8fda8.png)

In most of the plots a structure with ğ­ğ°ğ¨ ğœğ¥ğ®ğ¬ğ­ğğ«ğ¬ is again recognizable. Going ğ®ğ© ğšğ§ğ ğğ¨ğ°ğ§ ğ­ğ¡ğ ğ¬ğ­ğšğ¢ğ«ğ¬ ğŸğ¨ğ« ğ­ğ°ğ¨ ğ­ğ¢ğ¦ğğ¬ is likely for the experiment.
I will review the durations for this assumption with a small experiment on my stairs.


# SVM for Multiclass Classification 

![Human Activity Recognition using Smartphone Data with Machine Learning - Jupyter Notebook - Google Chrome 1_23_2022 6_19_32 PM](https://user-images.githubusercontent.com/85125898/150679174-37c95ecd-e04b-47af-967a-191b06a7b46a.png)

![download](https://user-images.githubusercontent.com/85125898/150679213-bc8f927e-6749-42fc-90a8-cc9d2b097419.png)

